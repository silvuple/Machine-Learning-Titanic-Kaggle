import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV


# Read titanic 'train' and 'test' DataFrames from pickle files.
train = pd.read_pickle('train.pkl')
test = pd.read_pickle('test.pkl')

# Pre-select features.
all_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 
                'Fare', 'Embarked', 'Last_name', 'Age_group', 
                'Relative_fare', 'Relative_age']
select_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Ticket', 'Last_name']
X = train.loc[:, select_features]
y = train['Survived']
X_predict = test.loc[:, select_features]

# Create train/test split.
X_train, X_test, y_train, y_test = train_test_split(X, y)

# 3. Use DecisionTreeClassifier to build prediction model.
# Apply  decision tree classifier model to training data.
dtc = DecisionTreeClassifier()
dtc.fit(X_train, y_train)

# Get mean accuracy and cross_validation mean accuracy scores.
accuracy_score = dtc.score(X_test, y_test)
cv_score = cross_val_score(dtc, X, y, cv=5).mean()
print("mean accuracy score is", accuracy_score)
print("mean cross_val accuracy score is", cv_score)

# Get feature importance (the higher, the more important).
features_importance = pd.DataFrame({'Feature':X.columns,
                                    'Importance':dtc.feature_importances_})
print("Feature importance:\n", features_importance)

# Search for best parameters with GridSearchCV.
param_grid = {'max_depth': [30, 50, 80, 100, None], 
              'max_features': ['auto', None], 
              'min_samples_leaf': [1, 2, 4, 8], 
              'min_samples_split': [2, 4]}
grid = GridSearchCV(dtc, param_grid, cv=5)
grid.fit(X, y)
print("grid best score is:", grid.best_score_)
print("grid best params are:", grid.best_params_)

# Predict for test data.
test['Survived'] = grid.predict(X_predict)

# Create csv submission file.
test.loc[:, ['PassengerId','Survived']].to_csv('submission_dtc.csv', index=False)
